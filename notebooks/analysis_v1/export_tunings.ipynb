{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.16/00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 11:58:02.647481: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all sub packages with ROOT dependence\n",
      "\n",
      "Applying ATLAS style settings...\n",
      "\n",
      "Applying ATLAS style settings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 11:58:03.930790: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-11 11:58:03.965292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 11:58:03.965480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1650 computeCapability: 7.5\n",
      "coreClock: 1.515GHz coreCount: 14 deviceMemorySize: 3.82GiB deviceMemoryBandwidth: 178.84GiB/s\n",
      "2022-01-11 11:58:03.965503: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-11 11:58:03.966707: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-11 11:58:03.967369: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-11 11:58:03.967627: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-11 11:58:03.969041: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-11 11:58:03.969779: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-11 11:58:03.972286: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-11 11:58:03.972428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 11:58:03.972695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 11:58:03.972846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2022-01-11 11:58:03.973278: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-11 11:58:03.998792: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499950000 Hz\n",
      "2022-01-11 11:58:03.999238: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x9a9b9f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-11 11:58:03.999257: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-11 11:58:04.040973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 11:58:04.041219: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x968bcf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-11 11:58:04.041232: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1650, Compute Capability 7.5\n",
      "2022-01-11 11:58:04.041398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 11:58:04.041577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1650 computeCapability: 7.5\n",
      "coreClock: 1.515GHz coreCount: 14 deviceMemorySize: 3.82GiB deviceMemoryBandwidth: 178.84GiB/s\n",
      "2022-01-11 11:58:04.041619: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-11 11:58:04.041653: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-11 11:58:04.041671: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-11 11:58:04.041686: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-11 11:58:04.041700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-11 11:58:04.041715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-11 11:58:04.041729: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-11 11:58:04.041787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 11:58:04.041975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 11:58:04.042122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2022-01-11 11:58:04.042145: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-11 11:58:04.349210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-11 11:58:04.349233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2022-01-11 11:58:04.349238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2022-01-11 11:58:04.349395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 11:58:04.349617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 11:58:04.349780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2649 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "from kolmov import crossval_table, crossval_fit_table, get_color_fader, fit_table\n",
    "from Gaugi import mkdir_p\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from multiprocessing import Process\n",
    "from time import sleep\n",
    "import saphyra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model, model_from_json\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from copy import deepcopy, copy\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_data_generator( path, pidname='el_lhmedium' ):  \n",
    "    import pandas as pd\n",
    "    from kepler import load\n",
    "    df = load(path)\n",
    "    # NOTE: Offline filter lhvloose -> lhmedium (as the training procedure)\n",
    "    df = df.loc[ ((df[pidname]==True) & (df.target==1.0)) | ((df.target==0) & (df['el_lhvloose']==0)) ]\n",
    "    return df\n",
    "\n",
    "\n",
    "def my_input_generator( df ):\n",
    "    '''\n",
    "    This function will generate the input for ringer models.\n",
    "\n",
    "    Arguments:\n",
    "    df: the dataframe\n",
    "    '''\n",
    "    col_names= ['trig_L2_cl_ring_%d'%i for i in range(100)]\n",
    "    rings = df[col_names].values.astype(np.float32)\n",
    "    \n",
    "    def norm1( data ):\n",
    "        norms = np.abs( data.sum(axis=1) )\n",
    "        norms[norms==0] = 1\n",
    "        return data/norms[:,None]\n",
    "    \n",
    "    rings = norm1(rings)\n",
    "    return [rings]\n",
    "\n",
    "def my_dec_generator_after( row, df , remove_last=True):\n",
    "    \n",
    "    from Gaugi import load as gload\n",
    "    file_name  = row.file_name.values[0]\n",
    "    i_init     = row.init.values[0]\n",
    "    i_sort     = row.sort.values[0]\n",
    "    model_idx  = row.model_idx.values[0]\n",
    "    tuned_data = gload(file_name)['tunedData']\n",
    "    slope = row.slope.values[0]\n",
    "    offset = row.offset.values[0]\n",
    "    for ituned in tuned_data:\n",
    "        if ((ituned['imodel'] == model_idx)\\\n",
    "            and (ituned['sort'] == i_sort) \\\n",
    "            and (ituned['init'] == i_init)):\n",
    "            sequence, weights = ituned['sequence'], ituned['weights']\n",
    "    model = tf.keras.models.model_from_json( json.dumps(sequence, separators=(',', ':')) ) #custom_objects={'RpLayer':RpLayer} )\n",
    "    model.set_weights( weights )\n",
    "    if remove_last:\n",
    "        model = tf.keras.models.Model(model.inputs, model.layers[-2].output)\n",
    "        \n",
    "    output = model.predict( my_input_generator(df), batch_size=4096 ).flatten()\n",
    "    avgmu = df.avgmu.values.flatten()\n",
    "    avgmu[avgmu>max_avgmu] = max_avgmu\n",
    "    avgmu[avgmu<min_avgmu] = min_avgmu\n",
    "    dec = np.greater(output, slope*avgmu + offset)\n",
    "    return dec\n",
    "\n",
    "def my_dec_generator( row, df ):\n",
    "    '''\n",
    "    This function will load a model from dataframe get their decision and return.\n",
    "\n",
    "    Arguments:\n",
    "    row: a dataframe row (used by kolmov)\n",
    "    df:  the dataframe that will be use to get the decision\n",
    "    '''\n",
    "    from Gaugi import load as gload\n",
    "    file_name  = row.file_name.values[0]\n",
    "    i_init     = row.init.values[0]\n",
    "    i_sort     = row.sort.values[0]\n",
    "    model_idx  = row.model_idx.values[0]\n",
    "    op_name    = row.op_name.values[0]\n",
    "    tuned_data = gload(file_name)['tunedData']\n",
    "    for ituned in tuned_data:\n",
    "        if ((ituned['imodel'] == model_idx)\\\n",
    "            and (ituned['sort'] == i_sort) \\\n",
    "            and (ituned['init'] == i_init)):\n",
    "            sequence, weights = ituned['sequence'], ituned['weights']\n",
    "            thr = ituned['history']['reference']['%s' %(op_name)]['threshold_op']\n",
    "    model = tf.keras.models.model_from_json( json.dumps(sequence, separators=(',', ':')) ) #custom_objects={'RpLayer':RpLayer} )\n",
    "    model.set_weights( weights )\n",
    "    \n",
    "    output = model.predict( my_input_generator(df), batch_size=4096 ).flatten()\n",
    "    dec = np.greater(output, thr)\n",
    "    return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "etbins  = [4, 7, 10, 15]\n",
    "etabins = [0.0, 0.8, 1.37, 1.54, 2.37, 2.50]\n",
    "kf = StratifiedKFold(n_splits=10, random_state=512, shuffle=True)\n",
    "\n",
    "cv_fit = crossval_fit_table( etbins, etabins, kf, my_data_generator, my_input_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_tag</th>\n",
       "      <th>et_bin</th>\n",
       "      <th>eta_bin</th>\n",
       "      <th>model_idx</th>\n",
       "      <th>sort</th>\n",
       "      <th>init</th>\n",
       "      <th>file_name</th>\n",
       "      <th>tuned_idx</th>\n",
       "      <th>op_name</th>\n",
       "      <th>max_sp_val</th>\n",
       "      <th>...</th>\n",
       "      <th>fa_val_total</th>\n",
       "      <th>pd_op_passed</th>\n",
       "      <th>fa_op_passed</th>\n",
       "      <th>pd_op_total</th>\n",
       "      <th>fa_op_total</th>\n",
       "      <th>slope</th>\n",
       "      <th>offset</th>\n",
       "      <th>fig_signal</th>\n",
       "      <th>fig_background</th>\n",
       "      <th>delta_ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v1.r0.mlp2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>/home/micael/Documents/NeuralRinger/Jpsiee/tun...</td>\n",
       "      <td>0</td>\n",
       "      <td>loose</td>\n",
       "      <td>0.939206</td>\n",
       "      <td>...</td>\n",
       "      <td>21591</td>\n",
       "      <td>27825</td>\n",
       "      <td>25582</td>\n",
       "      <td>28455</td>\n",
       "      <td>215903</td>\n",
       "      <td>-0.010263</td>\n",
       "      <td>-0.108604</td>\n",
       "      <td>/home/micael/Documents/NeuralRinger/Jpsiee/ana...</td>\n",
       "      <td>/home/micael/Documents/NeuralRinger/Jpsiee/ana...</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v1.r0.mlp2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/micael/Documents/NeuralRinger/Jpsiee/tun...</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.937434</td>\n",
       "      <td>...</td>\n",
       "      <td>21590</td>\n",
       "      <td>27986</td>\n",
       "      <td>28784</td>\n",
       "      <td>28455</td>\n",
       "      <td>215903</td>\n",
       "      <td>-0.010341</td>\n",
       "      <td>-0.313188</td>\n",
       "      <td>/home/micael/Documents/NeuralRinger/Jpsiee/ana...</td>\n",
       "      <td>/home/micael/Documents/NeuralRinger/Jpsiee/ana...</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v1.r0.mlp2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/micael/Documents/NeuralRinger/Jpsiee/tun...</td>\n",
       "      <td>0</td>\n",
       "      <td>tight</td>\n",
       "      <td>0.937434</td>\n",
       "      <td>...</td>\n",
       "      <td>21590</td>\n",
       "      <td>27986</td>\n",
       "      <td>28784</td>\n",
       "      <td>28455</td>\n",
       "      <td>215903</td>\n",
       "      <td>-0.010341</td>\n",
       "      <td>-0.313188</td>\n",
       "      <td>/home/micael/Documents/NeuralRinger/Jpsiee/ana...</td>\n",
       "      <td>/home/micael/Documents/NeuralRinger/Jpsiee/ana...</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v1.r0.mlp2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>/home/micael/Documents/NeuralRinger/Jpsiee/tun...</td>\n",
       "      <td>0</td>\n",
       "      <td>vloose</td>\n",
       "      <td>0.941184</td>\n",
       "      <td>...</td>\n",
       "      <td>21590</td>\n",
       "      <td>28148</td>\n",
       "      <td>34616</td>\n",
       "      <td>28455</td>\n",
       "      <td>215903</td>\n",
       "      <td>-0.006295</td>\n",
       "      <td>-0.692980</td>\n",
       "      <td>/home/micael/Documents/NeuralRinger/Jpsiee/ana...</td>\n",
       "      <td>/home/micael/Documents/NeuralRinger/Jpsiee/ana...</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v1.r0.mlp2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>/home/micael/Documents/NeuralRinger/Jpsiee/tun...</td>\n",
       "      <td>0</td>\n",
       "      <td>loose</td>\n",
       "      <td>0.923447</td>\n",
       "      <td>...</td>\n",
       "      <td>17908</td>\n",
       "      <td>8532</td>\n",
       "      <td>29537</td>\n",
       "      <td>8736</td>\n",
       "      <td>179082</td>\n",
       "      <td>-0.012149</td>\n",
       "      <td>-0.099207</td>\n",
       "      <td>/home/micael/Documents/NeuralRinger/Jpsiee/ana...</td>\n",
       "      <td>/home/micael/Documents/NeuralRinger/Jpsiee/ana...</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_tag  et_bin  eta_bin  model_idx  sort  init  \\\n",
       "0  v1.r0.mlp2       0        0          0     6     4   \n",
       "1  v1.r0.mlp2       0        0          0     0     2   \n",
       "2  v1.r0.mlp2       0        0          0     0     2   \n",
       "3  v1.r0.mlp2       0        0          0     8     3   \n",
       "4  v1.r0.mlp2       0        1          0     1     4   \n",
       "\n",
       "                                           file_name  tuned_idx op_name  \\\n",
       "0  /home/micael/Documents/NeuralRinger/Jpsiee/tun...          0   loose   \n",
       "1  /home/micael/Documents/NeuralRinger/Jpsiee/tun...          0  medium   \n",
       "2  /home/micael/Documents/NeuralRinger/Jpsiee/tun...          0   tight   \n",
       "3  /home/micael/Documents/NeuralRinger/Jpsiee/tun...          0  vloose   \n",
       "4  /home/micael/Documents/NeuralRinger/Jpsiee/tun...          0   loose   \n",
       "\n",
       "   max_sp_val  ...  fa_val_total  pd_op_passed  fa_op_passed  pd_op_total  \\\n",
       "0    0.939206  ...         21591         27825         25582        28455   \n",
       "1    0.937434  ...         21590         27986         28784        28455   \n",
       "2    0.937434  ...         21590         27986         28784        28455   \n",
       "3    0.941184  ...         21590         28148         34616        28455   \n",
       "4    0.923447  ...         17908          8532         29537         8736   \n",
       "\n",
       "   fa_op_total     slope    offset  \\\n",
       "0       215903 -0.010263 -0.108604   \n",
       "1       215903 -0.010341 -0.313188   \n",
       "2       215903 -0.010341 -0.313188   \n",
       "3       215903 -0.006295 -0.692980   \n",
       "4       179082 -0.012149 -0.099207   \n",
       "\n",
       "                                          fig_signal  \\\n",
       "0  /home/micael/Documents/NeuralRinger/Jpsiee/ana...   \n",
       "1  /home/micael/Documents/NeuralRinger/Jpsiee/ana...   \n",
       "2  /home/micael/Documents/NeuralRinger/Jpsiee/ana...   \n",
       "3  /home/micael/Documents/NeuralRinger/Jpsiee/ana...   \n",
       "4  /home/micael/Documents/NeuralRinger/Jpsiee/ana...   \n",
       "\n",
       "                                      fig_background  delta_ref  \n",
       "0  /home/micael/Documents/NeuralRinger/Jpsiee/ana...   0.000070  \n",
       "1  /home/micael/Documents/NeuralRinger/Jpsiee/ana...   0.000035  \n",
       "2  /home/micael/Documents/NeuralRinger/Jpsiee/ana...   0.000035  \n",
       "3  /home/micael/Documents/NeuralRinger/Jpsiee/ana...   0.000035  \n",
       "4  /home/micael/Documents/NeuralRinger/Jpsiee/ana...   0.000114  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_path  = '/home/micael/Documents/NeuralRinger/Jpsiee'\n",
    "\n",
    "tunes_path    = os.path.join(l_path, 'tunes')\n",
    "analysis_path = os.path.join(l_path, 'analysis')\n",
    "\n",
    "best_sorts_after = pd.read_csv(os.path.join(analysis_path, 'v1/r0/fitting/best_sorts_v1_with_mu_cor.csv'))\n",
    "best_sorts_after.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['v1.r0.mlp2'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sorts_after.train_tag.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 11:58:34,293 | Py.crossval_fit_table                   INFO Export all tuning configuration to ElectronRingerTightTriggerConfig.conf.\n",
      "2022-01-11 11:59:00,955 | Py.crossval_fit_table                   INFO Export all tuning configuration to ElectronRingerMediumTriggerConfig.conf.\n",
      "2022-01-11 11:59:27,618 | Py.crossval_fit_table                   INFO Export all tuning configuration to ElectronRingerLooseTriggerConfig.conf.\n",
      "2022-01-11 11:59:54,076 | Py.crossval_fit_table                   INFO Export all tuning configuration to ElectronRingerVeryLooseTriggerConfig.conf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n"
     ]
    }
   ],
   "source": [
    "min_avgmu = 16\n",
    "max_avgmu = 100\n",
    "\n",
    "model_name_format = 'data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electron{op}.et%d_eta%d'\n",
    "config_name_format = 'ElectronRinger{op}TriggerConfig.conf'\n",
    "op_capnames = ['Tight', 'Medium', 'Loose', 'VeryLoose']\n",
    "for idx, op in enumerate( ['tight','medium','loose','vloose'] ):\n",
    "    \n",
    "    cv_fit.export(best_sorts_after.loc[best_sorts_after.op_name==op], \n",
    "                  model_name_format.format(op=op_capnames[idx]), \n",
    "                  config_name_format.format(op=op_capnames[idx]), \n",
    "                  op, \n",
    "                  to_onnx     = True,\n",
    "                  remove_last = True,\n",
    "                  min_avgmu   = min_avgmu,\n",
    "                  max_avgmu   = max_avgmu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53005161f9b4b3a3f5eb7b597073d9782e8b33ca9b0d07505085a5a608ec4197"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('phd_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
